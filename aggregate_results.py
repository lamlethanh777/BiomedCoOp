"""
Aggregate and analyze evaluation results from CSV files.

This script reads the CSV files generated by log_results.py and produces
summary statistics grouped by different dimensions.

Usage:
    # Aggregate few-shot results by shots (across datasets)
    python aggregate_results.py --task few_shot --group-by shots --model BiomedCoOp_BiomedCLIP
    
    # Aggregate few-shot results by dataset (across shots)
    python aggregate_results.py --task few_shot --group-by dataset --model BiomedCoOp_BiomedCLIP
    
    # Aggregate base2new results by dataset
    python aggregate_results.py --task base2new --group-by dataset --model BiomedCoOp_BiomedCLIP
    
    # Export aggregated results to new CSV
    python aggregate_results.py --task few_shot --group-by shots --output aggregated_few_shot_by_shots.csv
"""

import argparse
import csv
import os
import sys
from collections import defaultdict
from pathlib import Path
import numpy as np


def compute_stats(values):
    """Compute mean and standard deviation."""
    if not values:
        return None, None
    
    values = [float(v) for v in values if v and v != 'N/A']
    if not values:
        return None, None
    
    mean = np.mean(values)
    std = np.std(values)
    return mean, std


def compute_ci95(values):
    """Compute 95% confidence interval."""
    if not values:
        return None
    
    values = [float(v) for v in values if v and v != 'N/A']
    if not values:
        return None
    
    return 1.96 * np.std(values) / np.sqrt(len(values))


def read_csv(csv_file):
    """Read CSV file and return list of rows."""
    if not os.path.exists(csv_file):
        print(f"Error: CSV file not found: {csv_file}")
        return []
    
    with open(csv_file, 'r', newline='') as f:
        reader = csv.DictReader(f)
        return list(reader)


def aggregate_few_shot_by_shots(data, ci95=False):
    """
    Aggregate few-shot results grouped by shot values.
    For each shot value, compute mean ± std across all datasets and seeds.
    """
    # Group by shots
    grouped = defaultdict(lambda: defaultdict(list))
    
    for row in data:
        shot = row['shot']
        grouped[shot]['accuracy'].append(row['accuracy'])
        if 'eval_time' in row and row['eval_time']:
            grouped[shot]['eval_time'].append(row['eval_time'])
    
    # Compute statistics
    results = []
    for shot in sorted(grouped.keys(), key=int):
        accuracies = grouped[shot]['accuracy']
        eval_times = grouped[shot]['eval_time']
        
        acc_mean, acc_std = compute_stats(accuracies)
        time_mean, time_std = compute_stats(eval_times)
        
        if ci95:
            acc_std = compute_ci95(accuracies)
        
        results.append({
            'shot': shot,
            'num_evaluations': len(accuracies),
            'accuracy_mean': f"{acc_mean:.2f}" if acc_mean else 'N/A',
            'accuracy_std': f"{acc_std:.2f}" if acc_std else 'N/A',
            'eval_time_mean': f"{time_mean:.2f}" if time_mean else 'N/A',
            'eval_time_std': f"{time_std:.2f}" if time_std else 'N/A',
        })
    
    return results


def aggregate_few_shot_by_dataset(data, ci95=False):
    """
    Aggregate few-shot results grouped by dataset.
    For each dataset, compute mean ± std across all shots and seeds.
    """
    # Group by dataset
    grouped = defaultdict(lambda: defaultdict(list))
    
    for row in data:
        dataset = row['dataset']
        grouped[dataset]['accuracy'].append(row['accuracy'])
        if 'eval_time' in row and row['eval_time']:
            grouped[dataset]['eval_time'].append(row['eval_time'])
    
    # Compute statistics
    results = []
    for dataset in sorted(grouped.keys()):
        accuracies = grouped[dataset]['accuracy']
        eval_times = grouped[dataset]['eval_time']
        
        acc_mean, acc_std = compute_stats(accuracies)
        time_mean, time_std = compute_stats(eval_times)
        
        if ci95:
            acc_std = compute_ci95(accuracies)
        
        results.append({
            'dataset': dataset,
            'num_evaluations': len(accuracies),
            'accuracy_mean': f"{acc_mean:.2f}" if acc_mean else 'N/A',
            'accuracy_std': f"{acc_std:.2f}" if acc_std else 'N/A',
            'eval_time_mean': f"{time_mean:.2f}" if time_mean else 'N/A',
            'eval_time_std': f"{time_std:.2f}" if time_std else 'N/A',
        })
    
    return results


def aggregate_few_shot_by_dataset_and_shot(data, ci95=False):
    """
    Aggregate few-shot results grouped by dataset and shot.
    For each (dataset, shot) pair, compute mean ± std across seeds.
    """
    # Group by (dataset, shot)
    grouped = defaultdict(lambda: defaultdict(list))
    
    for row in data:
        key = (row['dataset'], row['shot'])
        grouped[key]['accuracy'].append(row['accuracy'])
        if 'eval_time' in row and row['eval_time']:
            grouped[key]['eval_time'].append(row['eval_time'])
    
    # Compute statistics
    results = []
    for (dataset, shot) in sorted(grouped.keys()):
        accuracies = grouped[(dataset, shot)]['accuracy']
        eval_times = grouped[(dataset, shot)]['eval_time']
        
        acc_mean, acc_std = compute_stats(accuracies)
        time_mean, time_std = compute_stats(eval_times)
        
        if ci95:
            acc_std = compute_ci95(accuracies)
        
        results.append({
            'dataset': dataset,
            'shot': shot,
            'num_seeds': len(accuracies),
            'accuracy_mean': f"{acc_mean:.2f}" if acc_mean else 'N/A',
            'accuracy_std': f"{acc_std:.2f}" if acc_std else 'N/A',
            'eval_time_mean': f"{time_mean:.2f}" if time_mean else 'N/A',
            'eval_time_std': f"{time_std:.2f}" if time_std else 'N/A',
        })
    
    return results


def aggregate_base2new_by_dataset(data, ci95=False):
    """
    Aggregate base2new results grouped by dataset.
    For each dataset, compute mean ± std for base_acc, new_acc, and harmonic_mean.
    """
    # Group by dataset
    grouped = defaultdict(lambda: defaultdict(list))
    
    for row in data:
        dataset = row['dataset']
        if row.get('base_acc') and row['base_acc'] != 'N/A':
            grouped[dataset]['base_acc'].append(row['base_acc'])
        if row.get('new_acc') and row['new_acc'] != 'N/A':
            grouped[dataset]['new_acc'].append(row['new_acc'])
        if row.get('harmonic_mean') and row['harmonic_mean'] != 'N/A':
            grouped[dataset]['harmonic_mean'].append(row['harmonic_mean'])
        if 'eval_time' in row and row['eval_time']:
            grouped[dataset]['eval_time'].append(row['eval_time'])
    
    # Compute statistics
    results = []
    for dataset in sorted(grouped.keys()):
        base_accs = grouped[dataset]['base_acc']
        new_accs = grouped[dataset]['new_acc']
        h_means = grouped[dataset]['harmonic_mean']
        eval_times = grouped[dataset]['eval_time']
        
        base_mean, base_std = compute_stats(base_accs)
        new_mean, new_std = compute_stats(new_accs)
        h_mean, h_std = compute_stats(h_means)
        time_mean, time_std = compute_stats(eval_times)
        
        if ci95:
            base_std = compute_ci95(base_accs)
            new_std = compute_ci95(new_accs)
            h_std = compute_ci95(h_means)
        
        results.append({
            'dataset': dataset,
            'num_evaluations': len(h_means),
            'base_acc_mean': f"{base_mean:.2f}" if base_mean else 'N/A',
            'base_acc_std': f"{base_std:.2f}" if base_std else 'N/A',
            'new_acc_mean': f"{new_mean:.2f}" if new_mean else 'N/A',
            'new_acc_std': f"{new_std:.2f}" if new_std else 'N/A',
            'harmonic_mean_mean': f"{h_mean:.2f}" if h_mean else 'N/A',
            'harmonic_mean_std': f"{h_std:.2f}" if h_std else 'N/A',
            'eval_time_mean': f"{time_mean:.2f}" if time_mean else 'N/A',
            'eval_time_std': f"{time_std:.2f}" if time_std else 'N/A',
        })
    
    return results


def print_results(results, title):
    """Pretty print results."""
    print(f"\n{'='*80}")
    print(f"{title}")
    print(f"{'='*80}")
    
    if not results:
        print("No results to display.")
        return
    
    # Print as table
    headers = list(results[0].keys())
    
    # Calculate column widths
    widths = {h: len(h) for h in headers}
    for row in results:
        for h in headers:
            widths[h] = max(widths[h], len(str(row[h])))
    
    # Print header
    header_row = " | ".join(h.ljust(widths[h]) for h in headers)
    print(header_row)
    print("-" * len(header_row))
    
    # Print rows
    for row in results:
        print(" | ".join(str(row[h]).ljust(widths[h]) for h in headers))
    
    print(f"{'='*80}\n")


def save_results(results, output_file):
    """Save results to CSV file."""
    if not results:
        print("No results to save.")
        return
    
    with open(output_file, 'w', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=list(results[0].keys()))
        writer.writeheader()
        writer.writerows(results)
    
    print(f"✓ Results saved to {output_file}")


def main():
    parser = argparse.ArgumentParser(description='Aggregate evaluation results')
    parser.add_argument('--task', type=str, required=True, choices=['few_shot', 'base2new'],
                        help='Task type')
    parser.add_argument('--group-by', type=str, required=True,
                        choices=['shots', 'dataset', 'dataset_shot'],
                        help='How to group results')
    parser.add_argument('--model', type=str, default='BiomedCoOp_BiomedCLIP',
                        help='Model name (used to find CSV file)')
    parser.add_argument('--ci95', action='store_true',
                        help='Use 95% confidence interval instead of std')
    parser.add_argument('--output', type=str, default=None,
                        help='Output CSV file (optional)')
    
    args = parser.parse_args()
    
    # Determine CSV file
    if args.task == 'few_shot':
        csv_file = f"few_shot_{args.model}.csv"
    else:
        csv_file = f"base2new_{args.model}.csv"
    
    # Read data
    print(f"Reading {csv_file}...")
    data = read_csv(csv_file)
    
    if not data:
        print("No data found. Exiting.")
        sys.exit(1)
    
    print(f"Loaded {len(data)} evaluations")
    
    # Aggregate based on grouping
    results = None
    title = ""
    
    if args.task == 'few_shot':
        if args.group_by == 'shots':
            results = aggregate_few_shot_by_shots(data, args.ci95)
            title = "Few-Shot Results Grouped by Shots"
        elif args.group_by == 'dataset':
            results = aggregate_few_shot_by_dataset(data, args.ci95)
            title = "Few-Shot Results Grouped by Dataset"
        elif args.group_by == 'dataset_shot':
            results = aggregate_few_shot_by_dataset_and_shot(data, args.ci95)
            title = "Few-Shot Results Grouped by Dataset and Shot"
    else:  # base2new
        if args.group_by in ['dataset', 'dataset_shot']:
            results = aggregate_base2new_by_dataset(data, args.ci95)
            title = "Base2New Results Grouped by Dataset"
        else:
            print(f"Warning: group-by '{args.group_by}' not applicable for base2new. Using 'dataset'.")
            results = aggregate_base2new_by_dataset(data, args.ci95)
            title = "Base2New Results Grouped by Dataset"
    
    # Display results
    print_results(results, title)
    
    # Save if requested
    if args.output:
        save_results(results, args.output)


if __name__ == '__main__':
    main()
